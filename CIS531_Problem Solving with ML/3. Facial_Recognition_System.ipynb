{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "a26dc64b40cd9877e2bb93665a675ca1",
     "grade": false,
     "grade_id": "cell-e5835542f6f95e1f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>About this Project</h2>\n",
    "<p>In this project you will implement k-NN to classify images of faces. You will use the NumPy library to implement functions that will find nearest neighbors, calculate absolute loss, perform k-NN classification on a data set, and calculate the accuracy of your classifier.</p>\n",
    "\n",
    "\n",
    "<h3>Evaluation</h3>\n",
    "\n",
    "<p><strong>This project must be successfully completed and submitted in order to receive credit for this course. Your score on this project will be included in your final grade calculation.</strong></p>\n",
    "    \n",
    "<p>You are expected to write code where you see <em># YOUR CODE HERE</em> within the cells of this notebook. Not all cells will be graded; code input cells followed by cells marked with <em>#Autograder test cell</em> will be graded. Upon submitting your work, the code you write at these designated positions will be assessed using an \"autograder\" that will run all test cells to assess your code. You will receive feedback from the autograder that will identify any errors in your code. Use this feedback to improve your code if you need to resubmit. Be sure not to change the names of any provided functions, classes, or variables within the existing code cells, as this will interfere with the autograder. Also, remember to execute all code cells sequentially, not just those you’ve edited, to ensure your code runs properly.</p>\n",
    "    \n",
    "<p>You can resubmit your work as many times as necessary before the submission deadline. If you experience difficulty or have questions about this exercise, use the Q&A discussion board to engage with your peers or seek assistance from the instructor.</p>\n",
    "\n",
    "<p>Before starting your work, please review <a href=\"https://s3.amazonaws.com/ecornell/global/eCornellPlagiarismPolicy.pdf\">eCornell's policy regarding plagiarism</a> (the presentation of someone else's work as your own without source credit).</p>\n",
    "\n",
    "<h3>Submit Code for Autograder Feedback</h3>\n",
    "\n",
    "<p>Once you have completed your work on this notebook, you will submit your code for autograder review. Follow these steps:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Save your notebook.</strong></li>\n",
    "  <li><strong>Mark as Completed —</strong> In the blue menu bar along the top of this code exercise window, you’ll see a menu item called <strong>Education</strong>. In the <strong>Education</strong> menu, click <strong>Mark as Completed</strong> to submit your code for autograder/instructor review. This process will take a moment and a progress bar will show you the status of your submission.</li>\n",
    "\t<li><strong>Review your results —</strong> Once your work is marked as complete, the results of the autograder will automatically be presented in a new tab within the code exercise window. You can click on the assessment name in this feedback window to see more details regarding specific feedback/errors in your code submission.</li>\n",
    "  <li><strong>Repeat, if necessary —</strong> The Jupyter notebook will always remain accessible in the first tabbed window of the exercise. To reattempt the work, you will first need to click <strong>Mark as Uncompleted</strong> in the <strong>Education</strong> menu and then proceed to make edits to the notebook. Once you are ready to resubmit, follow steps one through three. You can repeat this procedure as many times as necessary.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "80f6d7f7e79cef44f62dbf23b25312a0",
     "grade": false,
     "grade_id": "cell-3e747cf31a39895c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>Import Libraries</h2>\n",
    "\n",
    "<p>Before you get started, you need to import a few libraries. You can do this by executing the following code. Remember, run code in a cell by selecting the cell, holding the shift key, and pressing enter/return.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "checksum": "9302968c21097dfc77554bc4838ec04d",
     "grade": false,
     "grade_id": "cell-c5f7e10c9b80a142",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're running python 3.6.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "from helper import *\n",
    "\n",
    "print('You\\'re running python %s' % sys.version.split(' ')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "4f8040d84604c6bf74c874f7c0dfdb3e",
     "grade": false,
     "grade_id": "cell-e3889b4538ffaef1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h2>k-Nearest Neighbors Implementation in Python</h2>\n",
    "\n",
    "<p>The goal of implementing your $k$-NN classifier is to build a classifier for face recognition. We have obtained some data, images of faces, for testing your code. The data resides in the file <code>faces.mat</code>, which holds the dataset for our exercises below.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "fc3a6ad4d67c07d1c09289bc8f51e5d1",
     "grade": false,
     "grade_id": "cell-a188cc90811f7b23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>We will refer to the training vectors as <b>xTr</b> with labels <b>yTr</b>. Our testing vectors are <b>xTe</b> with labels <b>yTe</b>.\n",
    "As a reminder, to predict the label or class of an image in <b>xTe</b>, we will look for the <i>k</i>-nearest neighbors in <b>xTr</b> and predict a label based on their labels in <b>yTr</b>. For evaluation, we will compare these labels against the true labels provided in <b>yTe</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "87b8563f652a9f41934877caf31c6f4c",
     "grade": false,
     "grade_id": "cell-cd644da84e9643c9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3> Visualizing the Data</h3>\n",
    "\n",
    "<p>Let us take a look at the data. The following script will take the first ten training images from the face dataset and visualize them. Run the code cell to see the visualized data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "checksum": "591f4723be22f4cb3bd019cae3d977cf",
     "grade": false,
     "grade_id": "cell-464aed1fe6c60140",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# xTr,yTr,xTe,yTe=loaddata(\"faces.mat\")\n",
    "\n",
    "# plt.figure(figsize=(11,8))\n",
    "# plotfaces(xTr[:9, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "f16600a84aac2b3649a3f36209b10f5d",
     "grade": false,
     "grade_id": "cell-bfa7bd73ad3567fb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "<h2>Implement k-NN for Facial Recognition</h2>\n",
    "<p>The following four project parts will step you through implementing each function necessary to build your facial recognition system.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "b58829670f6a55c42b04b920b9a18356",
     "grade": false,
     "grade_id": "cell-a7aef585a0780e8d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 1: Implement <b><code>findknn</code></b> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <b><code>findknn</code></b>, which should find the $k$ nearest neighbors of a set of vectors within a given training data set. The call of:</p>\n",
    "<pre>\n",
    " [I,D]=findknn(xTr,xTe,k);\n",
    "</pre> \n",
    "<p>should result in two matrices $I$ and $D$, both of dimensions $k\\times n$, where $n$ is the number of input vectors in <code>xTe</code>. The matrix $I(i,j)$ is the index of the $i^{th}$ nearest neighbor of the vector $xTe(j,:)$.</p>\n",
    "<p>\n",
    "So, for example, if we set <code>i=I(1,3)</code>, then <code>xTr(i,:)</code> is the first nearest neighbor of vector <code>xTe(3,:)</code>. The second matrix $D$ returns the corresponding distances. So $D(i,j)$ is the distance of $xTe(j,:)$ to its $i^{th}$ nearest neighbor.</p>\n",
    "<p>You can use the function <code>l2distance</code> from the previous exercise (which is readily available to you.) You may find <code>np.argsort(D,0)</code> and <code>np.sort(D,0)</code> useful when implementing <code>findknn</code>. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "checksum": "e7f911296db471f681f9904a978a4f3c",
     "grade": false,
     "grade_id": "cell-findknn",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def findknn(xTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function [indices,dists]=findknn(xTr,xTe,k);\n",
    "    \n",
    "    Finds the k nearest neighbors of xTe in xTr.\n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    indices = kxm matrix, where indices(i,j) is the i^th nearest neighbor of xTe(j,:)\n",
    "    dists = Euclidean distances to the respective nearest neighbors\n",
    "    \"\"\"\n",
    "    if k > len(xTr):\n",
    "        k = len(xTr)\n",
    "        \n",
    "    D=l2distance(xTe, xTr)\n",
    "    (m,n) = D.shape\n",
    "    \n",
    "    indices = []\n",
    "    dists = []\n",
    "    for i in range(m):\n",
    "        smallest_indices = np.argsort(D[i])\n",
    "        inds = smallest_indices[:k]\n",
    "        dis = D[i,smallest_indices[:k]]\n",
    "        indices.append(inds)\n",
    "        dists.append(dis)\n",
    "\n",
    "    indices = np.transpose(np.array(indices))\n",
    "    dists = np.transpose(np.array(dists))\n",
    "    return indices, dists\n",
    "#     # YOUR CODE HERE\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "checksum": "36b61efb8c36a40df2ddfca1d00758dd",
     "grade": false,
     "grade_id": "cell-findknn_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: knn_0 ... ✔ Passed!\n",
      "Running Test: knn_1 ... ✔ Passed!\n",
      "Running Test: knn_2 ... ✔ Passed!\n",
      "Running Test: knn_3 ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def knn_0():\n",
    "    # checking output types\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn(xTr,xTe,5) # compute indices and distances to the 5- nearest neighbors \n",
    "    # check if Ig is a matrix of integers, Dg a matrix of floats\n",
    "    test=(type(Ig)==np.ndarray)  & (type(Ig)==np.ndarray) & ((type(Dg[0][0])==np.float64) or (type(Dg[0][0])==np.float32)) & ((type(Dg[0][0])==np.float64) or (type(Dg[0][0])==np.float32))\n",
    "    return test\n",
    "\n",
    "def knn_1():\n",
    "    # checking output dimensions\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn(xTr,xTe,5) # compute indices and distances to the 5- nearest neighbors \n",
    "    test=(Ig.shape==(5,300)) & (Dg.shape==(5,300)) # test if output dimensions are correct\n",
    "    return test\n",
    "\n",
    "def knn_2():\n",
    "    # checking 1-NN accuracy\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,1) # compute indices and distances to the nearest neighbors with *our* code\n",
    "    Is,Ds = findknn(xTr,xTe,1) # Use *your* code\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds) # compare results\n",
    "    return test<1e-5 \n",
    "\n",
    "def knn_3():\n",
    "    # checking 3-NN accuracy\n",
    "    xTr = np.random.rand(500,10) # defininng 500 training data points \n",
    "    xTe = np.random.rand(300,10) # defining 300 testing data points\n",
    "    Ig,Dg = findknn_grader(xTr,xTe,3) # compute indices and distances to the 3-nearest neighbors with *our* code\n",
    "    Is,Ds = findknn(xTr,xTe,3) # Use *your* code\n",
    "    test = np.linalg.norm(Ig - Is) + np.linalg.norm(Dg - Ds) # compare results\n",
    "    return test<1e-5 \n",
    "\n",
    "runtest(knn_0,'knn_0')\n",
    "runtest(knn_1,'knn_1')\n",
    "runtest(knn_2,'knn_2')\n",
    "runtest(knn_3,'knn_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "checksum": "c6d3af4252fe82ca18671fd94806b5d7",
     "grade": true,
     "grade_id": "cell-knn_0_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "checksum": "ed3f5f555917d178af49ca4fde67779f",
     "grade": true,
     "grade_id": "cell-knn_1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "checksum": "f255c47c4b1a3fea9fb2a40829f493a2",
     "grade": true,
     "grade_id": "cell-knn_2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "checksum": "5245ff0ee1a930ee6375ee3c30433ce2",
     "grade": true,
     "grade_id": "cell-knn_3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "c07b50d3063493e3d6e94d76075b891f",
     "grade": false,
     "grade_id": "cell-da16c742b63ecb6e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>The following demo samples random points in 2D. If your <code>findknn</code> function is correctly implemented, you should be able to click anywhere on the plot to add a test point. The function should then draw direct connections from your test point to the k  nearest neighbors. Verify manually if your code is correct.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "checksum": "15dcf6edc6bc157d22320e83ff0c02eb",
     "grade": false,
     "grade_id": "cell-602dbde808c73078",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# visualize_knn_2D(findknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "0609475cf4ea0195091a53a851c47a0f",
     "grade": false,
     "grade_id": "cell-f271ff7465410f92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>We can visualize the k=3 nearest training neighbors of some of the test points (Click on the image to cycle through different test points).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "checksum": "604449f67a21dd9656dc032d40d21ea7",
     "grade": false,
     "grade_id": "cell-e5142d1f3cab1ce7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# visualize_knn_images(findknn, imageType='faces')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "b5cca1c2bc38a0f45d04454c4915fa87",
     "grade": false,
     "grade_id": "cell-b8955aefe424fd31",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 2: Implement <b><code>accuracy</code></b> [Graded]</h3>\n",
    "\n",
    "<p>The function <b><code>accuracy</code></b> should compute the accuracy of a classifier. The call of:</p>\n",
    "<pre>\n",
    "  result=accuracy(truth,preds);\n",
    "</pre>\n",
    "<p>should output the <b>accuracy</b> in variable <code>result</code>. The input variables <code>truth</code> and <code>preds</code> should contain vectors of true and predicted labels respectively.</p>\n",
    "<p>For example, the call:</p>\n",
    "<pre>\n",
    ">> accuracy([1 2 1 2],[1 2 1 1])\n",
    "</pre>\n",
    "<p>should return an accuracy of 0.75. Here, the true labels are 1,2,1,2 and the predicted labels are 1,2,1,1. So the first three examples are classified correctly, and the last one is wrong --- 75% accuracy.</p>\n",
    "<p>You may find the following functions helpful: <code>flatten()</code>, <code>np.mean()</code> and <code>np.abs()</code>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "checksum": "16d37290d4b73af4448c770c5b5290c7",
     "grade": false,
     "grade_id": "cell-accuracy",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(truth,preds):\n",
    "    \"\"\"\n",
    "    function output=accuracy(truth,preds)         \n",
    "    Analyzes the accuracy of a prediction against the ground truth\n",
    "    \n",
    "    Input:\n",
    "    truth = n-dimensional vector of true class labels\n",
    "    preds = n-dimensional vector of predictions\n",
    "    \n",
    "    Output:\n",
    "    accuracy = scalar (percent of predictions that are correct)\n",
    "    \"\"\"\n",
    "    \n",
    "    truth = truth.flatten()\n",
    "    preds = preds.flatten()\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if len(truth)==0 and len(preds)==0:\n",
    "        accuracy = 0\n",
    "        return accuracy\n",
    "    accuracy = np.mean(truth == preds)\n",
    "    return accuracy\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "checksum": "e70fb2d03ae685da6c0c17357a82df9d",
     "grade": false,
     "grade_id": "cell-accuracy_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: accuracy_test0 (types) ... ✔ Passed!\n",
      "Running Test: accuracy_test1 (exactness) ... ✔ Passed!\n",
      "Running Test: accuracy_test2 (exactness) ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def accuracy_test0():\n",
    "    # check type of output is correct\n",
    "    truth = np.array([1, 2, 3, 4])\n",
    "    preds = np.array([1, 2, 3, 0])\n",
    "    return type(accuracy(truth,preds))==np.float64\n",
    "\n",
    "def accuracy_test1():\n",
    "    # accuracy check on 4 sample data\n",
    "    truth = np.array([1, 2, 3, 4]) # define truth \n",
    "    preds = np.array([1, 2, 3, 0]) # define preds\n",
    "    return abs(accuracy(truth,preds) - 0.75)<1e-10 # check if accuracy is correct\n",
    "\n",
    "def accuracy_test2():\n",
    "    # accuracy check on random samples\n",
    "    p=np.random.rand(1,1000); # define random string of [0,1] as truth\n",
    "    truth=np.int16(p>0.5)\n",
    "    p2=p+np.random.randn(1,1000)*0.1; # define very similar version as preds\n",
    "    preds=np.int16(p2>0.5)\n",
    "    return abs(accuracy(truth,preds) - accuracy_grader(truth,preds))<1e-10 # check if accuracy is correct\n",
    "\n",
    "runtest(accuracy_test0,'accuracy_test0 (types)')\n",
    "runtest(accuracy_test1,'accuracy_test1 (exactness)')\n",
    "runtest(accuracy_test2,'accuracy_test2 (exactness)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "checksum": "e4ef5ced46c26052d377b89b03d14606",
     "grade": true,
     "grade_id": "cell-accuracy_test0",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs accuracy_test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "checksum": "89bb53345db13b3418ee315ee6fece78",
     "grade": true,
     "grade_id": "cell-accuracy_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs accuracy_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "checksum": "b735d3f9e23580e617db348e4c2a3727",
     "grade": true,
     "grade_id": "cell-accuracy_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs accuracy_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "2ad0f763b1f825cab514a51d37270aae",
     "grade": false,
     "grade_id": "cell-fcd1c8e4a92e349e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>Part 3: Implement <b><code>knnclassifier</code></b> [Graded]</h3>\n",
    "\n",
    "<p>Implement the function <b><code>knnclassifier</code></b>, which should perform $k$ nearest neighbor classification on a given test data set. The call:</p>\n",
    "<pre>preds=knnclassifier(xTr,yTr,xTe,k)</pre>\n",
    "<p>should output the predictions for the data in <code>xTe</code> i.e. <code>preds[i]</code> will contain the prediction for <code>xTe[i,:]</code>.</p>\n",
    "\n",
    "<p>You may find it helpful to use <code>flatten()</code> in the implementation of this function. It will also be useful to  refer back to the mode function you implemented in <a href=\"https://lms.ecornell.com/courses/1451693/modules/items/16187695\">Additional NumPy Exercises</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "checksum": "ca2e8dc1b8495bb5ee871698d8df90ac",
     "grade": false,
     "grade_id": "cell-knnclassifier",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def knnclassifier(xTr,yTr,xTe,k):\n",
    "    \"\"\"\n",
    "    function preds=knnclassifier(xTr,yTr,xTe,k);\n",
    "    \n",
    "    k-nn classifier \n",
    "    \n",
    "    Input:\n",
    "    xTr = nxd input matrix with n row-vectors of dimensionality d\n",
    "    xTe = mxd input matrix with m row-vectors of dimensionality d\n",
    "    k = number of nearest neighbors to be found\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    preds = predicted labels, ie preds(i) is the predicted label of xTe(i,:)\n",
    "    \"\"\"\n",
    "    # fix array shapes\n",
    "    yTr = yTr.flatten()\n",
    "\n",
    "    \n",
    "    indices, dists = findknn(xTr,xTe,k)\n",
    "    s,d = xTe.shape\n",
    "    \n",
    "    \n",
    "    vs = yTr[indices]\n",
    "    preds = np.array([mode(vs[:,i])[0] for i in range (s)]).flatten()\n",
    "\n",
    "    return preds\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "checksum": "ed9009f754bf7869e93625f3d7c4d955",
     "grade": false,
     "grade_id": "cell-knnclassifier_selftest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test: knn_classifier_test1 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test2 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test3 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test4 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test5 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test6 ... ✔ Passed!\n",
      "Running Test: knn_classifier_test7 ... ✔ Passed!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code\n",
    "\n",
    "def knn_classifier_test0():\n",
    "    # test if output is a numpy array, and of the right length\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    preds=knnclassifier(X,y,X,1)\n",
    "    return type(preds)==np.ndarray and preds.shape==(4,)\n",
    "\n",
    "\n",
    "def knn_classifier_test1():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    np.testing.assert_allclose(knnclassifier(X,y,X,1),y)\n",
    "    return np.testing.assert_allclose\n",
    "\n",
    "\n",
    "def knn_classifier_test2():\n",
    "    X = np.array([[1,0,0,1],[0,1,0,1]]).T\n",
    "    y = np.array([1,1,2,2])\n",
    "    y2 = np.array([2,2,1,1])\n",
    "    return np.array_equal(knnclassifier(X,y,X,3),y2)\n",
    "\n",
    "def knn_classifier_test3():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[-1,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2)\n",
    "\n",
    "def knn_classifier_test4():\n",
    "    X = np.array([[-4,-3,-2,2,3,4]]).T\n",
    "    y = np.array([1,1,1,2,2,2])\n",
    "    X2 = np.array([[0,1]]).T\n",
    "    y2 = np.array([1,2])\n",
    "    y3 = np.array([2,2])\n",
    "    return np.array_equal(knnclassifier(X,y,X2,2),y2) or np.array_equal(knnclassifier(X,y,X2,2),y3)\n",
    "\n",
    "def knn_classifier_test5():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,2,2])\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "def knn_classifier_test6():\n",
    "    X = np.random.rand(4,4)\n",
    "    y = np.array([1,2,1,2])\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "def knn_classifier_test7():\n",
    "    X = np.random.rand(10,100)\n",
    "    y = np.round(np.random.rand(10)).astype('int')\n",
    "    return accuracy(knnclassifier(X,y,X,1),y) == 1\n",
    "\n",
    "runtest(knn_classifier_test1,'knn_classifier_test1')\n",
    "runtest(knn_classifier_test2,'knn_classifier_test2')\n",
    "runtest(knn_classifier_test3,'knn_classifier_test3')\n",
    "runtest(knn_classifier_test4,'knn_classifier_test4')\n",
    "runtest(knn_classifier_test5,'knn_classifier_test5')\n",
    "runtest(knn_classifier_test6,'knn_classifier_test6')\n",
    "runtest(knn_classifier_test7,'knn_classifier_test7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbgrader": {
     "checksum": "c2496b1afcaaa297f815d7afb7ba5a6b",
     "grade": true,
     "grade_id": "knn_classifier_test1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "checksum": "37b2f89ee572ea3bd12c1404ec1cd3ea",
     "grade": true,
     "grade_id": "knn_classifier_test2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbgrader": {
     "checksum": "bdbebec62657d406b1ea1a66539b2c05",
     "grade": true,
     "grade_id": "knn_classifier_test3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbgrader": {
     "checksum": "74241c12a4aec4caef368df6cfabc33e",
     "grade": true,
     "grade_id": "knn_classifier_test4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "checksum": "c32b44875cc6c4ea9eec1f71faa13189",
     "grade": true,
     "grade_id": "knn_classifier_test5",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbgrader": {
     "checksum": "ca0276177c7fae1f950989d0f9ea682b",
     "grade": true,
     "grade_id": "knn_classifier_test6",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbgrader": {
     "checksum": "2a34110e0e2a460f349fdb0a1c553f7b",
     "grade": true,
     "grade_id": "knn_classifier_test7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder test cell - worth 1 point\n",
    "# runs knn_classifier_test7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "6ce10af79ae6a95da838a12e6ddf0570",
     "grade": false,
     "grade_id": "cell-e55bd469b83ac3e4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<p>You can compute the actual classification error on the test set by calling</p>\n",
    "<pre>\n",
    ">> accuracy(yTe,knnclassifier(xTr,yTr,xTe,3))\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "606d16100fb0289ee2dbffd6e5de63de",
     "grade": false,
     "grade_id": "cell-5239c4444c1d6114",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3><b>Part 4: Calculate Accuracy</b></h3>\n",
    "\n",
    "<p>The following script runs your $k$-nearest neighbor classifier over the faces and digits data set. The faces data set has $40$ classes and the digits data set has $10$. What classification accuracy would you expect from a random classifier?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "checksum": "4b7da90985c7c1175902544467ca61f3",
     "grade": false,
     "grade_id": "cell-922378fd6fbb2a87",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Recognition: (1-nn)\n",
      "You obtained 95.83% classification acccuracy in 0.0779 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Face Recognition: (1-nn)\")\n",
    "xTr,yTr,xTe,yTe=loaddata(\"faces.mat\") # load the data\n",
    "t0 = time.time()\n",
    "preds = knnclassifier(xTr,yTr,xTe,1)\n",
    "result=accuracy(yTe,preds)\n",
    "t1 = time.time()\n",
    "print(\"You obtained %.2f%% classification acccuracy in %.4f seconds\\n\" % (result*100.0,t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "checksum": "21488b814e6184abed4ff275666230f4",
     "grade": false,
     "grade_id": "cell-eb6a7d56ba0d4525",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "<h3>k-NN Boundary Visualization</h3>\n",
    "\n",
    "<p>To help give you a visual understanding of how the k-NN boundary is affected by $k$ and the specific dataset, feel free to play around with the visualization below.</p>\n",
    "<h4>Instructions:</h4>\n",
    "<ol>\n",
    "    <li>Run the cell below.</li>\n",
    "    <li>Click anywhere in the graph to add a negative class point.</li>\n",
    "    <li>Hold down <b>'p'</b> key and click anywhere in the graph to add a positive class point.</li>\n",
    "    <li>To increase $k$, hold down <b>'h'</b> key and click anywhere in the graph.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "checksum": "d63f10ca38ada8e8ee09b07710760f13",
     "grade": false,
     "grade_id": "cell-008b8e19515ab42b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# visualize_knn_boundary(knnclassifier)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
